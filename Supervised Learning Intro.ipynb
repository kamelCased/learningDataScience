{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised learning algorithms are trained using <strong>labeled</strong> examples, such as input where the desired output is known.\n",
    "\n",
    "* The network learns by receiving a set of <strong>inputs</strong> along with the corresponding correct <strong>outputs</strong>, and the algorithm <strong>learns by comparing its actual output with correct outputs</strong> to find errors. It then modifies the model accordingly.\n",
    "\n",
    "* Supervised learning is commonly used in applications where known historical data predicts likely future events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Process:\n",
    "1. Data Acquisition\n",
    "2. Data Cleaning\n",
    "3. Split to training and validation data\n",
    "4. Build & train model \n",
    "5. Validate the model (if needed, refine model parameters)\n",
    "6. Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "We can update the hyperparameters until our performance score is very high on the validation data. This is not represenattive of the model's performance on new unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "To fix this issue we split the data into 3 sets:\n",
    "1. Training data -- Used to train model parameters \n",
    "2. Validation data -- Used to determine what model hyperparameters to adjust\n",
    "3. Test data -- Used to get some final performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we finish training and validating our model, we need to identify key error metrics to determine how well our model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "A classification task is when the model attempts to classify categorical values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key classification model performance metrics are:\n",
    "* Accuracy \n",
    "* Recall\n",
    "* Precision \n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any classification task, your model can achieve one of two results:\n",
    "   * Correct Prediction\n",
    "   * Incorrect Prediction\n",
    "\n",
    "We repeat this process for all our test data. At the end, we have a count of all the correct and incorrect predictions. \n",
    "\n",
    "<small>Note: The key realization we need to make is that in the real world, not all incorrect or correct predictions hold equal value.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Accuracy\n",
    "\n",
    "Accuracy in classification problems is the number of correct predictions made by the model divided by the total number of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: If the model had to classify 100 images and it got 80 right. Then the accuracy is 0.8 or 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy is very useful when the target classes are <strong>well balanced</strong> (near equal number of examples for each target class).\n",
    "* Accuracy is <strong>not</strong> useful when the target classes are <strong>unbalanced</strong> (big difference in number of examples for each target class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall = Proportion of correctly labeled as positive cases among actually positive cases.\n",
    "\n",
    "Recall is the <strong>number of true positives</strong> divided by the <strong>number of true positives and false negatives<strong>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Precision = Proportion of actually positive cases among all cases labeled as positive\n",
    "\n",
    "Precision is the <strong>number of true positives</strong> divided by the <strong>number of true positives and false positives<strong>. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There is often a trade off between recall and precision. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where we want to find the optimal blend of precision and recall, we can combine the two metrics using the F1 score.\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall taking both metrics into account.\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the harmonic mean instead of the simple mean because it punishes extreme values. For instance, a classifier with 1.0 precision and 0.0 recall has a simple mean of 0.5, but a harmonic mean (and therefore F1 score) of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "We can also view all correctly and incorrectly classified data in the form of a confusion matrix. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  TP   |   FN   |  Recall\n",
    "----------------\n",
    "  FP   |   TN   | \n",
    "----------------\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a general sense, all 4 metrics are ways of comparing predicted values versus labeled values in some way. What constitutes good metrics depends on the situation.\n",
    "\n",
    "For instance, in disease diagnostics, it is crucial to minimize the false negatives (at the cost of increasing false positives). i.e. higher recall/lower precision.\n",
    "\n",
    "All in all machine leanring is a collaborative process where we should consult with domain experts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regression task is when the model attempts to predict continuous values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key regression model performance metrics are:\n",
    "* Mean Absolute Error\n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Mean Absolute Error\n",
    "\n",
    "The mean of the absolute value of errors. \n",
    "\n",
    "MAE = sum( | yPred - yTrue | ) / n  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the absolute value of errors. \n",
    "\n",
    "MAE = sum( | yPred - yTrue | ) / n  \n",
    "\n",
    "The issue with MAE is it doesn't punish large errors enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the squared value of errors. \n",
    "\n",
    "MSE = sum((yPred - yTrue)^2) / n  \n",
    "\n",
    "MSE punishes large errors more, making it more popular than MAE.\n",
    "\n",
    "The issue with MSE is that it squares the units as well. e.g. when we square the price difference, the error is expressed in terms of $^2 not $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square root of the mean of the squared value of errors. \n",
    "\n",
    "RMSE = sqrt(sum((yPred - yTrue)^2) / n)  \n",
    "\n",
    "RMSE punishes large errors and preserves the correct units. It is the most popular metric to express a regression model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer \"Is this RMSE good\", compare the RMSE to the average value of the label in your dataset. This will give you an intuition of its overall performance. Domain knowledge is important here too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Python\n",
    "\n",
    "We will be using `scikit-learn`\n",
    "\n",
    "Every model is exposed in scikit-learn via an <b>Estimator</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General import statement:\n",
    "`from sklearn.family import Estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statement example\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Instantiate the Estimator\n",
    "\n",
    "All the parameters of an Estimator can be set when you instantiate the Estimator, and have decent default values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(normalize=True)\n"
     ]
    }
   ],
   "source": [
    "#instantiate Linear Regression estimator\n",
    "model = LinearRegression(fit_intercept=True,normalize=True,copy_X=True,n_jobs=None)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Split data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create fake data\n",
    "import numpy as np\n",
    "X,y = np.arange(10).reshape((5,2)), np.arange(5)\n",
    "print(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2) (2, 2) (3,) (2,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.3)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Use the model to predict y values for X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 2.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(X_test)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.280369834735101e-16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model's RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test,p)\n",
    "mse**1/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
